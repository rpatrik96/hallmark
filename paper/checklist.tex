\section*{NeurIPS Paper Checklist}

\begin{enumerate}

\item {\bf Claims}
    \item[] Question: Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?
    \item[] Answer: \answerYes{}
    \item[] Justification: The abstract and introduction state four specific contributions (taxonomy, dataset, evaluation protocol, infrastructure), all of which are described in detail in the paper.

\item {\bf Limitations}
    \item[] Question: Does the paper discuss the limitations of the work performed by the authors?
    \item[] Answer: \answerYes{}
    \item[] Justification: \cref{sec:limitations} discusses dataset size, language coverage, synthetic vs.\ real hallucinations, API dependency, and temporal coverage.

\item {\bf Theory assumptions and proofs}
    \item[] Question: For each theoretical result, does the paper provide the full set of assumptions and a complete (and correct) proof?
    \item[] Answer: \answerNA{}
    \item[] Justification: The paper does not include theoretical results. The Plackett-Luce model is applied as an existing method with references to the original formulation.

\item {\bf Experimental result reproducibility}
    \item[] Question: Does the paper fully disclose all the information needed to reproduce the main experimental results of the paper to the extent that it affects the main claims and/or conclusions of the paper (regardless of whether the code and data are provided or not)?
    \item[] Answer: \answerYes{}
    \item[] Justification: All baselines are described in \cref{sec:baselines}, metrics are formally defined in \cref{sec:metrics}, and the evaluation protocol is fully specified. Pre-computed reference results are provided for rate-limited baselines.

\item {\bf Open access to data and code}
    \item[] Question: Does the paper provide open access to the data and code, with sufficient instructions to faithfully reproduce the main experimental results, as described in supplemental material?
    \item[] Answer: \answerYes{}
    \item[] Justification: The benchmark is open-source (MIT license), pip-installable, and includes all data, code, and CI workflows needed to reproduce results. Installation and usage instructions are provided in \cref{app:infrastructure}.

\item {\bf Experimental setting/details}
    \item[] Question: Does the paper specify all the training and test details (e.g., data splits, hyperparameters, how they were chosen, type of optimizer, etc.) necessary to understand the results?
    \item[] Answer: \answerYes{}
    \item[] Justification: Dataset splits are described in \cref{tab:stats}, baseline configurations in \cref{sec:baselines} and \cref{app:baselines}, and evaluation settings (timeout, rate-limit handling) in \cref{app:baselines}.

\item {\bf Experiment statistical significance}
    \item[] Question: Does the paper report error bars suitably and correctly defined or other appropriate information about the statistical significance of the experiments?
    \item[] Answer: \answerNo{}
    \item[] Justification: Baseline evaluations are deterministic (no random components), so error bars do not apply. We acknowledge the small sample sizes for some hallucination types in \cref{sec:limitations}.

\item {\bf Experiments compute resources}
    \item[] Question: For each experiment, does the paper provide sufficient information on the computer resources (type of compute workers, memory, time of execution) needed to reproduce the experiments?
    \item[] Answer: \answerYes{}
    \item[] Justification: Cost metrics (API calls per entry, entries per second) are reported in \cref{sec:cost}. No GPU is required. All baselines run on a single CPU.

\item {\bf Code of ethics}
    \item[] Question: Does the research conducted in the paper conform, in every respect, with the NeurIPS Code of Ethics?
    \item[] Answer: \answerYes{}
    \item[] Justification: The research supports scientific integrity. Dual-use considerations are discussed in \cref{sec:broader_impact}.

\item {\bf Broader impacts}
    \item[] Question: Does the paper discuss both potential positive societal impacts and negative societal impacts of the work performed?
    \item[] Answer: \answerYes{}
    \item[] Justification: \cref{sec:broader_impact} discusses positive impact (scientific integrity), dual-use risks, and accessibility.

\item {\bf Safeguards}
    \item[] Question: Does the paper describe safeguards that have been put in place for responsible release of data or models that have a high risk for misuse?
    \item[] Answer: \answerNA{}
    \item[] Justification: The benchmark contains bibliographic metadata only, which is already publicly available. It does not contain personal data, offensive content, or models with misuse potential.

\item {\bf Licenses for existing assets}
    \item[] Question: Are the creators or original owners of assets used in the paper properly credited and are the license and terms of use explicitly mentioned?
    \item[] Answer: \answerYes{}
    \item[] Justification: All external tools and data sources are cited. DBLP data is used under its open license. External baselines are cited with their respective licenses.

\item {\bf New assets}
    \item[] Question: Are new assets introduced in the paper well documented and is the documentation provided alongside the assets?
    \item[] Answer: \answerYes{}
    \item[] Justification: The dataset includes a datasheet (\cref{app:datasheet}), the code includes documentation and a CLI, and the package is pip-installable with versioned releases.

\item {\bf Crowdsourcing and research with human subjects}
    \item[] Question: For crowdsourcing experiments and research with human subjects, does the paper include the full text of instructions given to participants?
    \item[] Answer: \answerNA{}
    \item[] Justification: No crowdsourcing or human subjects research was conducted.

\item {\bf Institutional review board (IRB) approvals or equivalent for research with human subjects}
    \item[] Question: Does the paper describe potential risks incurred by study participants?
    \item[] Answer: \answerNA{}
    \item[] Justification: No human subjects research was conducted.

\item {\bf Declaration of LLM usage}
    \item[] Question: Does the paper describe the usage of LLMs if it is an important, original, or non-standard component of the core methods in this research?
    \item[] Answer: \answerYes{}
    \item[] Justification: LLMs are used for generating some hallucinated entries (described in \cref{sec:dataset}). This usage is documented as part of the dataset construction methodology.

\end{enumerate}

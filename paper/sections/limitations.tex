\section{Limitations}
\label{sec:limitations}

At 2,132 entries (1,214 hallucinated, with at least 30 instances per type per public split), the dataset provides improved statistical power per type but remains small relative to the full diversity of possible citation hallucinations.
With 30 instances per type per split, per-type metrics have narrower confidence intervals than the original 10-instance design (e.g., a type-level detection rate of 90\% has a 95\% Clopper-Pearson interval of [0.74, 0.98] rather than [0.55, 1.00]); we report per-type breakdowns with increased statistical confidence.
The hallucination prevalence differs across splits (52.2\% in dev, 63.4\% in test) due to scaling hallucinated entries independently per split and the addition of LLM-generated/real-world entries; prevalence-sensitive metrics should be interpreted with this caveat.
The benchmark covers only English-language BibTeX references.
The majority of hallucinated entries are synthetically generated via perturbation, though the benchmark now includes 222 LLM-generated entries (produced by prompting GPT-5.1 to generate plausible citations and verifying against CrossRef) and 17 real-world entries harvested from documented incidents (GPTZero/NeurIPS 2025, GhostCite, HalluCitation).
While these additions improve ecological validity, the LLM-generated entries skew toward certain types (notably \texttt{swapped\_authors}), and the real-world sample remains small.
Future versions should expand real-world coverage as more documented incidents become available.
Baseline performance depends on bibliographic API availability and coverage; results may shift as APIs evolve.
We did not evaluate commercial plagiarism detection tools (Turnitin, iThenticate), which focus on textual similarity rather than citation metadata verification.
Valid entries are drawn from 2018--2025 ML venues and may not generalize to other fields or time periods.
The community contribution system is designed to address these coverage limitations over time.
All synthetic entries are generated with a single fixed seed; we did not conduct seed-sensitivity analysis, though the deterministic generation ensures exact reproducibility.

\paragraph{DOI-presence distributional artifact.}
Approximately 62\% of valid entries lack DOI fields, while all \texttt{fabricated\_doi} entries contain DOIs by definition.
This distributional difference means DOI presence itself carries signal for this hallucination type, allowing DOI-based checks to achieve artificially high precision on \texttt{fabricated\_doi} entries.
We note this as a benchmark artifact that future versions should address through DOI enrichment of valid entries via CrossRef.
Per-type metrics (\cref{sec:per_type}) enable practitioners to assess tool performance separately on types with and without this artifact.

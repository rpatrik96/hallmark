from __future__ import annotations

# Real prestigious ML/AI venues — used by plausible_fabrication (tier3), batch generators,
# and pipeline stages (_common.py).
REAL_VENUES = [
    "NeurIPS",
    "ICML",
    "ICLR",
    "AAAI",
    "ACL",
    "CVPR",
    "ECCV",
    "EMNLP",
    "AISTATS",
    "UAI",
    "IJCAI",
    "COLT",
    "KDD",
    "WWW",
    "SIGIR",
]

# Venues that appear in VALID entries. Used to constrain hallucination generation
# so that hallucinated entries don't use venues absent from the valid set,
# which would create a trivial venue-based classification shortcut.
VALID_VENUES = [
    # Top ML conferences (scraped from DBLP)
    "NeurIPS",
    "ICML",
    "ICLR",
    "AAAI",
    "CVPR",
    "ACL",
    "EMNLP",
    "AISTATS",
    "NAACL",
    # Journals
    "J. Mach. Learn. Res.",
    "Mach. Learn.",
    "Trans. Mach. Learn. Res.",
]

# Single ML buzzwords used for simple chimeric title construction in batch.py.
ML_BUZZWORD_WORDS = [
    "Attention",
    "Transformer",
    "Diffusion",
    "Contrastive",
    "Self-Supervised",
    "Prompt",
    "Retrieval-Augmented",
    "Foundation Model",
    "Chain-of-Thought",
    "Mixture of Experts",
]

# Full chimeric title templates — plausible ML paper titles used by pipeline stages.
CHIMERIC_TITLE_TEMPLATES = [
    "Self-Attention Mechanisms for Low-Resource Temporal Reasoning",
    "Cross-Modal Representation Learning in Heterogeneous Domains",
    "Contrastive Self-Supervised Methods for Dense Prediction",
    "Few-Shot Meta-Learning with Task-Adaptive Initialization",
    "Diffusion-Based Generative Models for Molecular Design",
    "Neural Architecture Search with Hardware Constraints",
    "Multi-Task Transfer Learning Across Modalities",
    "Graph Neural Network Architectures for Combinatorial Optimization",
    "Prompt-Tuning Strategies for Instruction-Following Models",
    "Retrieval-Augmented Generation for Long-Form Question Answering",
    "Vision-Language Alignment via Contrastive Pre-Training",
    "Causal Inference Methods for Treatment Effect Estimation",
    "Federated Learning with Heterogeneous Client Distributions",
    "Sparse Mixture-of-Experts for Efficient Inference",
    "Test-Time Adaptation Under Distribution Shift",
    "Token-Free Language Modeling with Character-Level Transformers",
    "Reward Modeling for Alignment of Large Language Models",
    "Low-Rank Adaptation for Parameter-Efficient Fine-Tuning",
    "Continual Learning Without Catastrophic Forgetting",
    "Efficient Attention via Linear Complexity Approximations",
    "Denoising Diffusion Probabilistic Models for Image Restoration",
    "Self-Supervised Speech Representation Learning",
    "Equivariant Neural Networks for Physical Simulations",
    "Bayesian Optimization for Hyperparameter Tuning",
    "Multi-Agent Reinforcement Learning in Cooperative Settings",
    "Knowledge Distillation for Model Compression",
    "Adversarial Robustness Through Certified Defenses",
    "Neural Radiance Fields for Novel View Synthesis",
    "Temporal Graph Networks for Dynamic Interaction Modeling",
    "Data Augmentation Strategies for Low-Resource NLP",
    "Hierarchical Reinforcement Learning with Temporal Abstraction",
    "Attention Mechanisms for Sequential Decision Making",
    "Uncertainty Quantification in Deep Neural Networks",
    "Efficient Transformer Architectures for Long Sequences",
    "Multi-Modal Fusion for Visual Question Answering",
    "Domain Adaptation via Adversarial Training",
    "Neural Program Synthesis from Input-Output Examples",
    "Explainable AI Through Attention Visualization",
    "Graph Transformers for Molecular Property Prediction",
    "Few-Shot Learning via Prototypical Networks",
    "Meta-Reinforcement Learning for Task Distribution",
    "Causal Discovery from Observational Data",
    "Self-Supervised Learning for Medical Imaging",
    "Neural Architecture Search with Evolutionary Algorithms",
    "Multimodal Pre-Training for Vision and Language",
    "Efficient Neural Network Pruning Techniques",
    "Gradient-Based Meta-Learning for Quick Adaptation",
    "Contrastive Learning for Self-Supervised Representation",
    "Neural Ordinary Differential Equations for Time Series",
    "Adversarial Training for Distribution Robustness",
    "Knowledge Graph Completion via Relation Prediction",
    "Transformer-Based Models for Code Generation",
    "Curriculum Learning for Complex Task Training",
    "Neural Scene Representation and Rendering",
    "Multi-Agent Communication with Emergent Protocols",
    "Active Learning Strategies for Label Efficiency",
    "Deep Learning for Combinatorial Optimization Problems",
    "Variational Autoencoders for Anomaly Detection",
    "Neural Machine Translation with Attention",
    "Graph Neural Networks for Traffic Forecasting",
    "Reinforcement Learning from Human Feedback",
    "Diffusion Models for High-Resolution Image Synthesis",
    "Vision Transformers for Dense Prediction Tasks",
    "Neural Architecture Search Under Resource Constraints",
    "Self-Supervised Speech Representation via Contrastive Learning",
    "Probabilistic Forecasting with Deep Learning",
    "Neural Tangent Kernel Theory and Applications",
    "Multi-Objective Optimization in Neural Architecture Search",
    "Geometric Deep Learning on Manifolds and Graphs",
    "Neural Sequence-to-Sequence Models with Copy Mechanism",
]

# Provably fictional DOI prefixes (99990+, 88880+, 77770+, 66660+ ranges are unregistered).
# Do NOT include any real registrant prefixes (e.g. 10.48550 is arXiv, 10.1145 is ACM).
FAKE_DOI_PREFIXES = [
    "10.99990",
    "10.99991",
    "10.99992",
    "10.99993",
    "10.99994",
    "10.99995",
    "10.99996",
    "10.99997",
    "10.99998",
    "10.99999",
    "10.88880",
    "10.88881",
    "10.88882",
    "10.88883",
    "10.77770",
    "10.77771",
    "10.77772",
    "10.77773",
    "10.66660",
    "10.66661",
]

FAKE_VENUES = [
    "International Conference on Advanced AI Systems",
    "Journal of Computational Intelligence and Applications",
    "Workshop on Emerging Methods in Deep Learning",
    "Transactions on Neural Computing Paradigms",
    "Symposium on Frontier Artificial Intelligence Research",
    "Annual Conference on Machine Learning Innovations",
    "IEEE International Conference on Cognitive Computing",
    "Pacific Rim Symposium on Neural Information Systems",
    "European Workshop on Probabilistic Machine Learning",
    "ACM Conference on Automated Reasoning and Learning",
    "International Journal of Adaptive Computation",
    "Workshop on Scalable Representation Learning",
    "Conference on Foundations of Intelligent Systems",
    "Journal of Theoretical and Applied AI Research",
    "International Symposium on Data-Driven Discovery",
    "Transactions on Autonomous Learning Systems",
    "Workshop on Trustworthy AI and Robustness",
    "Conference on Multimodal Learning and Perception",
    "Annual Symposium on Efficient Deep Learning",
    "Journal of Neural Architecture and Optimization",
    "International Conference on Generative Modeling",
    "Workshop on Causal Inference in Machine Learning",
    "Conference on Language Models and Understanding",
    "Symposium on Geometric Deep Learning Methods",
    "Pacific Conference on Knowledge Representation",
    "Journal of Reinforcement Learning and Control",
    "International Workshop on Federated AI Systems",
    "Conference on Bio-Inspired Computing and AI",
    "Transactions on Computer Vision Applications",
    "Annual Workshop on AI Safety and Alignment",
    "Symposium on Graph Neural Network Research",
    "International Conference on Continual Learning",
    "Journal of Explainable Artificial Intelligence",
    "Workshop on Low-Resource Language Processing",
    "Conference on Bayesian Deep Learning Methods",
    "International Symposium on AI for Science",
    "Transactions on Self-Supervised Representation Learning",
    "Workshop on Embodied Intelligence and Robotics",
    "Conference on Privacy-Preserving Machine Learning",
    "Journal of Time Series Analysis and Forecasting",
    "Symposium on Neuro-Symbolic AI Integration",
    "International Conference on Quantum Machine Learning",
    "Workshop on Foundation Models and Adaptation",
    "Conference on Algorithmic Fairness in AI",
    "Annual Conference on Spatial Intelligence",
    "Journal of Statistical Machine Learning Theory",
    "Workshop on Scientific Machine Learning",
    "Symposium on Decision-Making Under Uncertainty",
    "International Conference on Intelligent Automation",
    "Conference on Emergent Communication in AI",
    "IEEE Symposium on Adaptive Neural Systems",
    "Workshop on Memory-Augmented Neural Networks",
    "International Journal of Deep Learning Research",
    "Conference on Structured Prediction Methods",
    "Symposium on Transfer Learning Paradigms",
    "ACM Workshop on Neural Architecture Design",
    "Transactions on Meta-Learning and Adaptation",
    "Conference on Distributed Machine Learning",
    "Journal of Adversarial Machine Learning",
    "International Workshop on Interpretable Models",
    "Symposium on Online Learning Theory",
    "Conference on Attention Mechanisms and Transformers",
    "Workshop on Multi-Agent Learning Systems",
    "Journal of Optimization in Neural Networks",
    "International Conference on Semantic Understanding",
    "Symposium on Probabilistic Reasoning",
    "Conference on Zero-Shot and Few-Shot Learning",
    "Workshop on Neural Information Retrieval",
    "Transactions on Language Model Architectures",
    "International Journal of Representation Learning",
    "Conference on Active Learning Methods",
    "Symposium on Regularization Techniques",
    "Workshop on Curriculum Learning Strategies",
    "Journal of Uncertainty Estimation",
    "International Conference on Model Compression",
    "Conference on Synthetic Data Generation",
    "Symposium on Contrastive Learning Methods",
    "Workshop on Attention and Memory Networks",
    "Transactions on Graph Representation Learning",
    "International Journal of Neural Inference",
    "Conference on Prompt Engineering and Design",
    "Symposium on Test-Time Adaptation Methods",
    "Workshop on Domain Generalization",
    "Journal of Efficient Neural Architectures",
    "International Conference on Multimodal Integration",
    "Conference on Neural Theorem Proving",
    "Symposium on World Models and Planning",
    "Workshop on Latent Variable Models",
    "Transactions on Neural Rendering",
    "International Journal of Metric Learning",
    "Conference on Hierarchical Learning Systems",
    "Symposium on Energy-Based Models",
    "Workshop on Neural Differential Equations",
    "Journal of Sequence Modeling",
    "International Conference on Equivariant Networks",
    "Conference on Disentangled Representations",
    "Symposium on Neural Scaling Laws",
    "Workshop on Sparse Neural Networks",
    "Transactions on Instruction Following Models",
    "International Journal of Context Learning",
    "Conference on Reward Learning and Alignment",
    "Symposium on Compositional Generalization",
]

FAKE_AUTHORS = [
    "Wei Zhang and Priya Patel and James Brown",
    "Maria Santos and Hiroshi Tanaka",
    "Ahmed Hassan and Sarah O'Brien and Raj Gupta",
    "K. Mueller and L. Johansson",
    "Yusuf Ali and Elena Popova and David Lee",
    "R. Kumar and S. Nakamura and T. Fischer",
    "Jing Liu and Carlos Ramirez",
    "Olga Ivanova and Pierre Dubois and Min-Soo Kim",
    "M. Chen and A. Kowalski and B. Okafor",
    "Fatima Al-Rashid and Kenji Yamamoto",
    "Dmitri Volkov and Aisha Mbeki and Luca Rossi",
    "J. Andersen and C. Morales",
    "Ravi Sharma and Mei-Ling Wu and Thomas Schmidt",
    "P. Novak and H. Sato and F. Osei",
    "Soo-Jin Park and Rafael Costa",
    "N. Petersen and Y. Taniguchi and A. Mensah",
    "Ling Chen and Amara Diallo and Viktor Horvat",
    "Q. Wang and D. Fernandez and E. Kimura",
    "Hassan Ibrahim and Sofia Kowalczyk and Jun-Ho Lee",
    "Isabella Romano and Kwame Mensah and Yuki Sato",
    "Lars Bergström and Aisha Ndiaye and Chen Wei",
    "Mateo Garcia and Nadia Petrova and Hiroshi Yamada",
    "Elena Vasquez and Tariq Al-Mansour and Min-Ji Park",
    "Viktor Sokolov and Amina Diop and Takeshi Nakamura",
    "Gabriela Silva and Omar Farah and Yuna Choi",
    "Andreas Schneider and Zainab Ahmed and Kenji Tanaka",
    "Lucia Moretti and Jamal Williams and Hye-Jin Kim",
    "Nikolai Ivanov and Fatou Sow and Akira Suzuki",
    "Carmen Rodriguez and Kwasi Osei and Mei-Ling Huang",
    "Stefan Müller and Amara Koné and Taro Watanabe",
    "Valentina Costa and Ibrahim Kone and Soo-Yeon Lee",
    "Dimitri Popov and Nadine Dubois and Yuki Matsumoto",
    "Rosa Martinez and Adebayo Adeyemi and Ji-Woo Park",
    "Henrik Larsen and Yasmin Hassan and Haruto Nakano",
    "Francesca Bianchi and Mustafa Ali and Hana Taniguchi",
    "Pavel Novotny and Fatima Ndoye and Ryota Kobayashi",
    "Ana Santos and Kwame Asante and Min-Seo Kim",
    "Mikhail Petrov and Amina Traoré and Kaito Yamamoto",
    "Giulia Romano and Youssef Benali and Sora Takahashi",
    "Jan Kowalski and Zara Ibrahim and Ren Watanabe",
    "Marta Fernandez and Abdi Mohamed and Aiko Suzuki",
    "Boris Volkov and Fatoumata Diallo and Riku Nakamura",
    "Cristina Lopez and Tariq Hussein and Yui Tanaka",
    "Andrei Ivanov and Mariama Sow and Haruki Sato",
    "Bianca Silva and Omar Sharif and Ayumi Yamada",
    "Dmitry Kozlov and Aissatou Diop and Sota Kobayashi",
    "Elena Garcia and Adama Toure and Kaede Matsumoto",
    "Igor Sokolov and Ndeye Ndiaye and Yuta Nakano",
    "Laura Martinez and Hassan Ahmed and Rina Taniguchi",
    "Maxim Petrov and Fatou Kone and Sho Watanabe",
    "Nina Rodriguez and Ibrahim Diallo and Kenta Yamamoto",
    "Oleg Volkov and Aminata Seck and Daiki Suzuki",
    "Paula Santos and Yusuf Ibrahim and Hiro Takahashi",
    "Roman Ivanov and Zeynab Hassan and Ryo Nakamura",
    "Sara Lopez and Abdou Diop and Yuki Sato",
    "Tomas Novotny and Fatouma Traore and Takumi Tanaka",
    "Ulyana Petrova and Oumar Ndiaye and Shun Yamada",
    "Vera Sokolova and Mamadou Kone and Kaito Matsumoto",
    "Xavier Costa and Awa Sow and Ren Kobayashi",
    "Yana Ivanova and Cheikh Diallo and Sora Nakano",
    "Zara Fernandez and Boubacar Toure and Aoi Watanabe",
    "Ali Rahman and Ingrid Johansson and Yuto Suzuki",
    "Beatriz Silva and Jamal Ibrahim and Hana Yamamoto",
    "Carlos Garcia and Khadija Hassan and Riku Tanaka",
    "Diana Martinez and Lamine Ndiaye and Saki Sato",
    "Emilio Rodriguez and Maimouna Diop and Yui Nakamura",
    "Fatima Lopez and Ndongo Kone and Haruki Yamada",
    "Gabriel Santos and Oumou Sow and Kaede Kobayashi",
    "Hector Fernandez and Penda Diallo and Yuta Matsumoto",
    "Ibrahim Costa and Ramata Traore and Sota Nakano",
    "Jasmin Novotny and Saliou Ndiaye and Rina Taniguchi",
    "Karim Petrov and Thiam Toure and Kenta Watanabe",
    "Leila Ivanov and Ury Seck and Sho Yamamoto",
    "Malik Sokolov and Viviane Kone and Daiki Suzuki",
    "Noor Rodriguez and Waly Diop and Hiro Takahashi",
    "Oscar Lopez and Xadi Sow and Ryo Nakamura",
    "Petra Silva and Yacouba Ndiaye and Yuki Sato",
    "Quinn Martinez and Zeinab Kone and Takumi Tanaka",
    "Rashid Fernandez and Aida Traore and Shun Yamada",
    "Salma Santos and Binta Diallo and Kaito Matsumoto",
    "Tariq Garcia and Coumba Toure and Ren Kobayashi",
    "Umi Rodriguez and Dieynaba Seck and Sora Nakano",
    "Vera Costa and Elhadj Ndiaye and Aoi Watanabe",
    "Walid Novotny and Fanta Kone and Yuto Suzuki",
    "Yasmin Petrov and Gnima Sow and Hana Yamamoto",
    "Zahra Ivanov and Habib Diop and Riku Tanaka",
    "Amir Sokolov and Ina Diallo and Saki Sato",
    "Basma Lopez and Juma Traore and Yui Nakamura",
    "Cyril Silva and Kadiatou Ndiaye and Haruki Yamada",
    "Dalia Martinez and Lassana Toure and Kaede Kobayashi",
    "Elias Fernandez and Mame Seck and Yuta Matsumoto",
    "Farah Santos and Ndiaga Kone and Sota Nakano",
    "Ghazi Garcia and Oury Sow and Rina Taniguchi",
    "Huda Rodriguez and Papa Ndiaye and Kenta Watanabe",
    "Imran Costa and Qader Diop and Sho Yamamoto",
    "Jana Novotny and Rokhaya Kone and Daiki Suzuki",
    "Kareem Petrov and Safiatou Traore and Hiro Takahashi",
    "Laila Ivanov and Tidiane Diallo and Ryo Nakamura",
]

HYBRID_FAKE_AUTHORS = [
    "Michael Zhang and Jennifer Liu and Robert Chen",
    "Anna Petrov and Carlos Martinez and Yuki Nakamura",
    "Thomas Anderson and Sophia Kumar and Daniel Park",
    "Isabella Rossi and Ahmed Ali and Emma Williams",
    "Lucas Brown and Maria Garcia and Kevin Nguyen",
    "Olga Sokolova and James Wright and Mei Lin",
    "Henrik Larsson and Fatima Benali and Takeshi Ito",
    "Priya Chatterjee and Marco Bianchi and Soo-Yeon Choi",
    "David Okonkwo and Laura Fischer and Wei-Ting Hsu",
    "Amir Rezaei and Rachel Thompson and Kenji Morita",
    "Elena Vasquez and Patrick Murphy and Zhi-Yong Xu",
    "Nadia Kowalczyk and Samuel Adjei and Yuki Watanabe",
    "Oscar Herrera and Anya Krishnan and Felix Bauer",
    "Christine Dufour and Jamal Henderson and Hana Suzuki",
    "Dmitri Orlov and Amelia Santos and Jun-Ho Kwon",
]

PLAUSIBLE_FIRST_NAMES = [
    "Wei",
    "Yuki",
    "Sofia",
    "Alex",
    "Nina",
    "Gabriel",
    "Tomoko",
    "Leonardo",
    "Kexin",
    "Jieyu",
    "Pavel",
    "Daphne",
    "Elena",
    "Aditya",
    "Ziqian",
    "Ryuichi",
    "Tamara",
    "Jessica",
    "Ruiqi",
    "Anton",
    "Wenda",
    "Robin",
    "Yuntao",
    "Hanlin",
    "Tiancheng",
    "Georg",
    "Minjoon",
    "Ilia",
    "Fei",
    "Lin",
    "Ekin",
    "Shuang",
    "Yuxin",
    "Zhouhan",
    "Yao",
]

PLAUSIBLE_LAST_NAMES = [
    "Zhang",
    "Tanaka",
    "Andersson",
    "Wu",
    "Kowalski",
    "Moreira",
    "Watanabe",
    "Ricci",
    "Pei",
    "Chen",
    "Tokmakov",
    "Cornelisse",
    "Vorontsova",
    "Grover",
    "Zhong",
    "Yamamoto",
    "Broderick",
    "Hamrick",
    "Gao",
    "Obukhov",
    "Chu",
    "Rombach",
    "Bai",
    "Goh",
    "Zhao",
    "Martius",
    "Seo",
    "Sucholutsky",
    "Sha",
    "Gui",
    "Cubuk",
    "Li",
    "Sindhwani",
    "Fu",
    "Gu",
]

PLAUSIBLE_METHODS = [
    "Contrastive Learning",
    "Self-Supervised Pre-Training",
    "Variational Inference",
    "Reinforcement Learning",
    "Meta-Learning",
    "Knowledge Distillation",
    "Prompt Tuning",
    "Bayesian Optimization",
    "Curriculum Learning",
    "Federated Averaging",
    "Neural Architecture Search",
    "Gradient Descent",
    "Spectral Normalization",
    "Data Augmentation",
    "Domain Adaptation",
    "Transfer Learning",
    "Active Learning",
    "Few-Shot Learning",
    "Zero-Shot Learning",
    "Multi-Task Learning",
    "Adversarial Training",
    "Continual Learning",
    "Online Learning",
    "Causal Inference",
    "Information Bottleneck",
]

PLAUSIBLE_DOMAINS = [
    "Vision Transformers",
    "Large Language Models",
    "Graph Neural Networks",
    "Point Cloud Processing",
    "Medical Image Analysis",
    "Autonomous Driving",
    "Molecular Property Prediction",
    "Speech Recognition",
    "Recommender Systems",
    "Time Series Forecasting",
    "Object Detection",
    "Semantic Segmentation",
    "Text Classification",
    "Image Generation",
    "Robot Navigation",
    "Question Answering",
    "Neural Rendering",
    "Protein Structure Prediction",
    "Code Generation",
    "Dialogue Systems",
    "Video Understanding",
    "Multi-Modal Retrieval",
    "Drug Discovery",
    "Traffic Prediction",
    "Anomaly Detection",
]

PLAUSIBLE_PROPERTIES = [
    "Robust",
    "Efficient",
    "Scalable",
    "Calibrated",
    "Interpretable",
    "Fair",
    "Privacy-Preserving",
    "Communication-Efficient",
    "Sample-Efficient",
    "Parameter-Efficient",
    "Provably Correct",
    "Certifiably Robust",
    "Memory-Efficient",
    "Data-Efficient",
    "Compute-Efficient",
    "Adaptive",
    "Generalizable",
    "Trustworthy",
    "Explainable",
    "Energy-Efficient",
]

PLAUSIBLE_NOUNS = [
    "Representations",
    "Embeddings",
    "Features",
    "Predictions",
    "Distributions",
    "Policies",
    "Architectures",
    "Objectives",
    "Gradients",
    "Attention Mechanisms",
    "Loss Functions",
    "Activation Functions",
    "Optimization Strategies",
    "Regularization Techniques",
    "Sampling Methods",
    "Inference Procedures",
    "Training Dynamics",
    "Model Weights",
    "Hidden States",
    "Latent Codes",
]

PLAUSIBLE_SETTINGS = [
    "Low-Resource Settings",
    "Non-Stationary Environments",
    "High-Dimensional Spaces",
    "Heterogeneous Data",
    "Label-Scarce Regimes",
    "Streaming Data",
    "Multi-Task Settings",
    "Cross-Domain Scenarios",
    "Partial Observability",
    "Noisy Labels",
    "Imbalanced Datasets",
    "Distribution Shift",
    "Out-of-Distribution Detection",
    "Long-Tailed Recognition",
    "Adversarial Perturbations",
    "Missing Data",
    "Limited Supervision",
    "Real-Time Constraints",
    "Cold-Start Problems",
    "Extreme Classification",
]

NEAR_MISS_NOUN_SYNONYMS: dict[str, str] = {
    "learning": "training",
    "training": "learning",
    "network": "architecture",
    "architecture": "network",
    "model": "framework",
    "framework": "model",
    "method": "approach",
    "approach": "method",
    "system": "pipeline",
    "pipeline": "system",
    "analysis": "study",
    "study": "analysis",
    "detection": "recognition",
    "recognition": "detection",
    "generation": "synthesis",
    "synthesis": "generation",
    "estimation": "prediction",
    "prediction": "estimation",
    "classification": "categorization",
    "categorization": "classification",
    "representation": "embedding",
    "embedding": "representation",
    "inference": "reasoning",
    "reasoning": "inference",
    "segmentation": "partitioning",
    "partitioning": "segmentation",
    "regularization": "penalization",
    "penalization": "regularization",
    "search": "exploration",
    "exploration": "search",
    "bounds": "guarantees",
    "guarantees": "bounds",
    "loss": "objective",
    "objective": "loss",
    "task": "problem",
    "problem": "task",
    "survey": "review",
    "review": "survey",
    "score": "metric",
    "metric": "score",
    "bottleneck": "limitation",
    "limitation": "bottleneck",
    "corruption": "perturbation",
    "perturbation": "corruption",
    "design": "construction",
    "construction": "design",
    "planning": "scheduling",
    "scheduling": "planning",
    "attention": "focus",
    "focus": "attention",
    "need": "require",
    "require": "need",
    "information": "knowledge",
    "knowledge": "information",
    "image": "visual",
    "visual": "image",
    "language": "linguistic",
    "linguistic": "language",
    "optimization": "tuning",
    "tuning": "optimization",
    "convergence": "stability",
    "stability": "convergence",
    "transformation": "mapping",
    "mapping": "transformation",
    "dimension": "feature",
    "feature": "dimension",
    "kernel": "filter",
    "filter": "kernel",
    "encoder": "compressor",
    "compressor": "encoder",
    "decoder": "reconstructor",
    "reconstructor": "decoder",
    "mechanism": "scheme",
    "scheme": "mechanism",
    "technique": "strategy",
    "strategy": "technique",
    "evaluation": "assessment",
    "assessment": "evaluation",
    "performance": "accuracy",
    "accuracy": "performance",
    "alignment": "matching",
    "matching": "alignment",
    "augmentation": "enhancement",
    "enhancement": "augmentation",
    "compression": "reduction",
    "reduction": "compression",
    "distillation": "compression",
    "aggregation": "pooling",
    "pooling": "aggregation",
    "interpolation": "blending",
    "blending": "interpolation",
    "retrieval": "extraction",
    "extraction": "retrieval",
    "fusion": "integration",
    "integration": "fusion",
    "decomposition": "factorization",
    "factorization": "decomposition",
    "refinement": "improvement",
    "improvement": "refinement",
}

NEAR_MISS_ADJ_SYNONYMS: dict[str, str] = {
    "robust": "resilient",
    "resilient": "robust",
    "efficient": "scalable",
    "scalable": "efficient",
    "optimal": "approximate",
    "approximate": "optimal",
    "deep": "hierarchical",
    "hierarchical": "deep",
    "adversarial": "competitive",
    "competitive": "adversarial",
    "distributed": "decentralized",
    "decentralized": "distributed",
    "adaptive": "dynamic",
    "dynamic": "adaptive",
    "contrastive": "comparative",
    "comparative": "contrastive",
    "deterministic": "stochastic",
    "stochastic": "deterministic",
    "neural": "learned",
    "learned": "neural",
    "causal": "structural",
    "structural": "causal",
    "latent": "hidden",
    "hidden": "latent",
    "exact": "precise",
    "precise": "exact",
    "fast": "rapid",
    "rapid": "fast",
    "unsupervised": "self-supervised",
    "self-supervised": "unsupervised",
    "inverse": "reverse",
    "reverse": "inverse",
    "sparse": "compact",
    "compact": "sparse",
    "dense": "rich",
    "rich": "dense",
    "generative": "probabilistic",
    "probabilistic": "generative",
    "discriminative": "predictive",
    "predictive": "discriminative",
    "continuous": "smooth",
    "smooth": "continuous",
    "discrete": "categorical",
    "categorical": "discrete",
    "local": "spatial",
    "spatial": "local",
    "global": "universal",
    "universal": "global",
    "temporal": "sequential",
    "sequential": "temporal",
    "modular": "compositional",
    "compositional": "modular",
    "differentiable": "smooth",
    "lightweight": "compact",
    "heavy": "complex",
    "complex": "heavy",
    "simple": "basic",
    "basic": "simple",
    "advanced": "sophisticated",
    "sophisticated": "advanced",
    "interpretable": "explainable",
    "explainable": "interpretable",
    "fair": "unbiased",
    "unbiased": "fair",
}

NEAR_MISS_PREP_SYNONYMS: dict[str, str] = {
    "via": "through",
    "through": "via",
    "towards": "for",
    "for": "towards",
    "with": "using",
    "using": "with",
    "across": "over",
    "over": "across",
    "under": "beneath",
    "beneath": "under",
}

NEAR_MISS_SAFE_PLURAL_ROOTS = {
    "model",
    "network",
    "method",
    "bound",
    "guarantee",
    "constraint",
    "representation",
    "feature",
    "tree",
    "approach",
    "system",
    "attack",
    "image",
    "embedding",
    "distribution",
    "score",
    "prediction",
    "algorithm",
    "graph",
    "function",
    "layer",
    "node",
    "weight",
    "task",
    "objective",
    "problem",
    "gradient",
    "sample",
}

NEAR_MISS_ABBREVIATIONS: dict[str, str] = {
    "RL": "Reinforcement Learning",
    "NLP": "Natural Language Processing",
    "GAN": "Generative Adversarial Network",
    "CNN": "Convolutional Neural Network",
    "RNN": "Recurrent Neural Network",
    "VAE": "Variational Autoencoder",
    "SGD": "Stochastic Gradient Descent",
    "MLP": "Multi-Layer Perceptron",
    "GNN": "Graph Neural Network",
    "LLM": "Large Language Model",
}

HYBRID_SWAP_WORDS: dict[str, str] = {
    "learning": "training",
    "neural": "deep",
    "network": "model",
    "efficient": "optimized",
    "robust": "stable",
    "novel": "new",
    "approach": "method",
    "framework": "system",
    "attention": "focus",
    "transformer": "architecture",
}

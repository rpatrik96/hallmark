{"bibtex_key": "llm_swapped_authors_0_dosovitskiy2020", "bibtex_type": "article", "fields": {"title": "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale", "author": "Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil", "journal": "arXiv preprint arXiv:2010.11929", "year": "2020", "doi": "10.48550/arXiv.2010.11929", "url": "https://doi.org/10.48550/arXiv.2010.11929"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for a paper on vision transformers. Include the DOI.'. Verification: Authors don't match CrossRef: 'Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil' vs 'Alexy Beyer and Luca Alexy'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{dosovitskiy2020vit,\n  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},\n  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},\n  journal={arXiv preprint arXiv:2010.11929},\n  year={2020},\n  doi={10.48550/arXiv.2010.11929},\n  url={https://doi.org/10.48550/arXiv.2010.11929}\n}\n```\n\n### Key details:\n- **Paper**: The foundational Vision Transformer (ViT) work\n- **DOI**: `10.48550/arXiv.2010.11929`\n- **Conference**: Published at ICLR 2021 (originally arXiv preprint in 2020)\n- **Why this entry?**: This is the most cited and influential paper introducing pure transformer architectures for computer vision.\n\n### Notes:\n1. Uses `\n}"}
{"bibtex_key": "llm_swapped_authors_1_vaswani2017atte", "bibtex_type": "article", "fields": {"author": "Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin", "title": "Attention Is All You Need", "journal": "Advances in Neural Information Processing Systems", "volume": "30", "year": "2017", "pages": "5998--6008", "doi": "10.48550/arXiv.1706.03762", "url": "https://arxiv.org/abs/1706.03762"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX entry with DOI for 'Attention Is All You Need'.'. Verification: Authors don't match CrossRef: 'Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin' vs 'Patrick Mineault'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{vaswani2017attention,\n  author    = {Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin},\n  title     = {Attention Is All You Need},\n  journal   = {Advances in Neural Information Processing Systems},\n  volume    = {30},\n  year      = {2017},\n  pages     = {5998--6008},\n  doi       = {10.48550/arXiv.1706.03762},\n  url       = {https://arxiv.org/abs/1706.03762}\n}\n```\n\n### Key Notes:\n1. **DOI**: `10.48550/arXiv.1706.03762` (resolves to the arXiv preprint, which is the most widely referenced version).  \n2. **Conference**: Published in *NeurIPS 2017* (Volume 30).  \n3. **URL**: Direct link to the arXiv version for easy access.  \n4. **Special Character**: `{\\L}` ensures \"Łukasz\" renders correctly in BibTeX.\n\n### Alternative Format (if you prefer `\n}"}
{"bibtex_key": "llm_wrong_venue_0_LastnameYear", "bibtex_type": "inproceedings", "fields": {"author": "Firstname Lastname and Coauthor Name", "title": "{Deep Learning with Neural Systems", "booktitle": "Proceedings of the International Conference on Advanced Neural Systems", "year": "2023", "pages": "123--145", "address": "City, Country", "month": "July", "publisher": "Publisher Name", "doi": "10.xxxx/xxxxxx", "url": "https://doi.org/10.xxxx/xxxxxx", "note": "Optional note"}, "label": "HALLUCINATED", "hallucination_type": "wrong_venue", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for a paper from the International Conference on Advanced Neural Systems.'. Verification: Venue doesn't match CrossRef: 'Proceedings of the International Conference on Advanced Neural Systems' vs 'Advanced Series in Circuits and Systems'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": true, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{LastnameYear,\n  author    = {Firstname Lastname and Coauthor Name},\n  title     = {Your Paper Title Here},\n  booktitle = {Proceedings of the International Conference on Advanced Neural Systems},\n  year      = {2023},\n  pages     = {123--145},\n  address   = {City, Country},\n  month     = {July},\n  publisher = {Publisher Name},\n  doi       = {10.xxxx/xxxxxx},\n  url       = {https://doi.org/10.xxxx/xxxxxx},\n  note      = {Optional note}\n}\n```\n\n**Key fields to customize**:\n1. `LastnameYear`: Citation key (e.g., `Smith2023`)\n2. `author`: Full author names\n3. `title`: Paper title in curly braces\n4. `year`: Conference year\n5. `pages`: Start and end page numbers\n6. `address`: Conference location (City, Country)\n7. `month`: Conference month\n8. `publisher`: Proceedings publisher\n9. `doi`/`url`: Digital Object Identifier or URL\n\n**Important notes**:\n- Use double braces `{}` for values with special characters (e.g., `title = {{Deep Learning with Neural Systems}}`)\n- The `booktitle` field remains constant for this conference\n- Remove optional fields like `note` if unused\n- For preprints without DOI, use `eprint` or `archivePrefix` fields instead\n\nExample with sample data:\n```bibtex\n}"}
{"bibtex_key": "llm_swapped_authors_1_Author2023Emerg", "bibtex_type": "inproceedings", "fields": {"author": "Author, Alice and Coauthor, Bob", "title": "A Novel Framework for Explainable AI in Healthcare", "booktitle": "Proceedings of the Workshop on Emerging AI Methods (EAIM)", "year": "2023", "month": "December", "publisher": "Association for the Advancement of Artificial Intelligence", "address": "Virtual Event", "pages": "123--135", "url": "https://eaim-workshop.org/papers/123", "doi": "10.1234/567.890"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me a BibTeX entry from the Workshop on Emerging AI Methods.'. Verification: Authors don't match CrossRef: 'Author, Alice and Coauthor, Bob' vs 'Aman Kataria and Sita Rani'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{Author2023EmergingAIMethods,\n  author    = {Author, Alice and Coauthor, Bob},\n  title     = {A Novel Framework for Explainable AI in Healthcare},\n  booktitle = {Proceedings of the Workshop on Emerging AI Methods (EAIM)},\n  year      = {2023},\n  month     = {December},\n  publisher = {Association for the Advancement of Artificial Intelligence},\n  address   = {Virtual Event},\n  pages     = {123--135},\n  url       = {https://eaim-workshop.org/papers/123},\n  doi       = {10.1234/567.890}\n}\n```\n\n### Notes:\n1. Replace `Author2023EmergingAIMethods` with a meaningful citation key.  \n2. If the workshop is affiliated with a larger conference (e.g., NeurIPS, ICML), include the parent conference in `booktitle`, e.g.,  \n   `booktitle = {Proceedings of the 2023 Conference on Neural Information Processing Systems (NeurIPS) Workshop on Emerging AI Methods}`.  \n3. Confirm the exact workshop name, year, publisher, and DOI from the publication.  \n4. For unpublished/preprint workshop papers, use `\n}"}
{"bibtex_key": "llm_swapped_authors_0_AuthorLastnameY", "bibtex_type": "inproceedings", "fields": {"author": "Lastname, Firstname and Lastname, Firstname and Lastname, Firstname", "title": "A Catchy Title for Your Machine Learning Paper", "booktitle": "Proceedings of the XXth Conference on Machine Learning (PMLR/ICML/NeurIPS/ICLR)", "year": "YYYY", "pages": "XXXX--XXXX", "url": "https://proceedings.mlr.press/vXX/...", "doi": "10.18653/v1.2023.acl-main.312", "arxiv": "XXXX.YYYYY", "code": "https://github.com/...", "website": "https://project-page.com...", "note": "\\textit{Optional award citation"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a generic BibTeX entry template for a machine learning paper.'. Verification: Authors don't match CrossRef: 'Lastname, Firstname and Lastname, Firstname and Lastname, Firstname' vs 'Zaihan Yang and Brian D. Davison'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{AuthorLastnameYYYY,\n  author    = {Lastname, Firstname and Lastname, Firstname and Lastname, Firstname},\n  title     = {A Catchy Title for Your Machine Learning Paper},\n  booktitle = {Proceedings of the XXth Conference on Machine Learning (PMLR/ICML/NeurIPS/ICLR)},\n  year      = {YYYY},\n  pages     = {XXXX--XXXX},\n  url       = {https://proceedings.mlr.press/vXX/...},\n  doi       = {10.18653/v1.2023.acl-main.312},\n  arxiv     = {XXXX.YYYYY},  % Optional for preprints\n  code      = {https://github.com/...},  % Optional\n  website   = {https://project-page.com...},  % Optional\n  note      = {\\textit{Optional award citation}},  % Optional (e.g., \"Best Paper Award\")\n}\n```\n\n**Key fields:**\n- `author`: Use \"and\" between authors\n- `title`: Title case with curly braces around proper nouns\n- `booktitle`: Conference name (use official abbreviation)\n- `year`: Publication year\n- `pages`: Page range (if available)\n- `url`/`doi`: Persistent identifier (prefer DOI when available)\n- Optional fields: arxiv, code, website, note\n\n**For journal papers**, use `\n}"}
{"bibtex_key": "llm_swapped_authors_1_vaswani2017atte", "bibtex_type": "inproceedings", "fields": {"title": "Attention Is All You Need", "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia", "booktitle": "Advances in Neural Information Processing Systems", "volume": "30", "pages": "5998--6008", "year": "2017", "publisher": "Curran Associates, Inc.", "url": "https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf", "archiveprefix": "arXiv", "eprint": "1706.03762"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me an example BibTeX entry for a deep learning paper.'. Verification: Authors don't match CrossRef: 'Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia' vs 'Patrick Mineault'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{vaswani2017attention,\n  title     = {Attention Is All You Need},\n  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia},\n  booktitle = {Advances in Neural Information Processing Systems},\n  volume    = {30},\n  pages     = {5998--6008},\n  year      = {2017},\n  publisher = {Curran Associates, Inc.},\n  url       = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},\n  archiveprefix = {arXiv},\n  eprint    = {1706.03762}\n}\n```\n\n**Key components explained:**\n1. **Entry Type**: `\n}"}
{"bibtex_key": "llm_swapped_authors_2_mnih2013playing", "bibtex_type": "article", "fields": {"title": "Playing Atari with Deep Reinforcement Learning", "author": "Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin", "journal": "arXiv preprint arXiv:1312.5602", "year": "2013", "url": "https://arxiv.org/abs/1312.5602"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Create a sample BibTeX citation for a paper on reinforcement learning.'. Verification: Authors don't match CrossRef: 'Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin' vs 'Ken Zheng'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{mnih2013playing,\n  title     = {Playing Atari with Deep Reinforcement Learning},\n  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},\n  journal   = {arXiv preprint arXiv:1312.5602},\n  year      = {2013},\n  url       = {https://arxiv.org/abs/1312.5602}\n}\n```\n\n**Key components explained:**\n- `\n}"}
{"bibtex_key": "llm_swapped_authors_0_perez2029quantu", "bibtex_type": "inproceedings", "fields": {"title": "Quantum Transformers for Efficient Sequence Modeling", "author": "Perez, Maria A. and Zhang, Wei and Kiani, Bobak T.", "booktitle": "Proceedings of the 17th International Conference on Learning Representations (ICLR)", "year": "2029", "url": "https://openreview.net/forum?id=Abc1dEf2GH", "note": "Oral Presentation"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me BibTeX for papers from ICLR 2029 on quantum machine learning.'. Verification: Authors don't match CrossRef: 'Perez, Maria A. and Zhang, Wei and Kiani, Bobak T.' vs 'Pascal Ekin'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{perez2029quantumtransformers,\n  title     = {Quantum Transformers for Efficient Sequence Modeling},\n  author    = {Perez, Maria A. and Zhang, Wei and Kiani, Bobak T.},\n  booktitle = {Proceedings of the 17th International Conference on Learning Representations (ICLR)},\n  year      = {2029},\n  url       = {https://openreview.net/forum?id=Abc1dEf2GH},  % Hypothetical URL\n  note      = {Oral Presentation}\n}"}
{"bibtex_key": "llm_swapped_authors_0_hinton2023block", "bibtex_type": "inproceedings", "fields": {"title": "Decentralized Deep Learning: A Blockchain-Based Framework for Secure Model Training", "author": "Hinton, Geoffrey E. and Chen, Yifan and Gupta, Rajesh", "booktitle": "Advances in Neural Information Processing Systems", "year": "2023", "volume": "36", "pages": "12345--12360", "url": "https://proceedings.neurips.cc/paper/2023/hash/...", "abstract": "This paper proposes a novel blockchain-integrated framework to decentralize deep learning training, ensuring data integrity, model transparency, and resistance to tampering via smart contracts. We demonstrate..."}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for Geoffrey Hinton's paper on blockchain applications in deep learning.'. Verification: Authors don't match CrossRef: 'Hinton, Geoffrey E. and Chen, Yifan and Gupta, Rajesh' vs 'Gitanjali Bhimrao Yadav and Jayashri Bagade'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{hinton2023blockchain,\n  title     = {Decentralized Deep Learning: A Blockchain-Based Framework for Secure Model Training},\n  author    = {Hinton, Geoffrey E. and Chen, Yifan and Gupta, Rajesh},\n  booktitle = {Advances in Neural Information Processing Systems},\n  year      = {2023},\n  volume    = {36},\n  pages     = {12345--12360},\n  url       = {https://proceedings.neurips.cc/paper/2023/hash/...},\n  abstract  = {This paper proposes a novel blockchain-integrated framework to decentralize deep learning training, ensuring data integrity, model transparency, and resistance to tampering via smart contracts. We demonstrate...}\n}\n```\n\n### Key Details (Fictional):\n- **Title:** A plausible title combining blockchain and deep learning themes.  \n- **Authors:** Geoffrey Hinton (primary) with fictional co-authors.  \n- **Venue:** NeurIPS (a top ML conference).  \n- **Year:** 2023 (recent, given blockchain's rise).  \n- **URL/Abstract:** Placeholder links/descriptions typical of ML papers.  \n\n### If you need a real Hinton paper:\nFor authentic references, consider his seminal works like:  \n```bibtex\n}"}
{"bibtex_key": "llm_swapped_authors_1_lecun1998gradie", "bibtex_type": "article", "fields": {"title": "Gradient-Based Learning Applied to Document Recognition", "author": "LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and Haffner, Patrick", "journal": "Proceedings of the IEEE", "volume": "86", "number": "11", "pages": "2278--2324", "year": "1998", "doi": "10.1109/5.726791"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for Yann LeCun's paper on quantum neural networks.'. Verification: Authors don't match CrossRef: 'LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and Haffner, Patrick' vs 'Y. Lecun and L. Bottou and Y. Bengio and P. Haffner'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": true, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{lecun1998gradient,\n  title   = {Gradient-Based Learning Applied to Document Recognition},\n  author  = {LeCun, Yann and Bottou, L{\\'e}on and Bengio, Yoshua and Haffner, Patrick},\n  journal = {Proceedings of the IEEE},\n  volume  = {86},\n  number  = {11},\n  pages   = {2278--2324},\n  year    = {1998},\n  doi     = {10.1109/5.726791}\n}\n```\n\n### 2. If You Meant a Quantum Neural Network Paper by Other Authors:\nLeCun hasn't published directly on quantum NNs, but here are influential QNN papers:\n- **Farhi et al. (2018):**  \n  ```bibtex\n}"}
{"bibtex_key": "llm_swapped_authors_1_devlin-etal-201", "bibtex_type": "inproceedings", "fields": {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina", "booktitle": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)", "month": "June", "year": "2019", "pages": "4171--4186", "url": "https://aclanthology.org/N19-1423", "doi": "10.18653/v1/N19-1423"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for BERT from CVPR 2019.'. Verification: Authors don't match CrossRef: 'Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina' vs 'Dongjie Zhu'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{devlin-etal-2019-bert,\n  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT)},\n  month     = {June},\n  year      = {2019},\n  pages     = {4171--4186},\n  url       = {https://aclanthology.org/N19-1423},\n  doi       = {10.18653/v1/N19-1423}\n}\n```\n\n### Notes:\n1. **CVPR vs. NAACL**:  \n   CVPR focuses on computer vision, while BERT (a **natural language processing** model) was published at NAACL-HLT 2019.\n\n2. **If you need a CVPR 2019 paper *related* to BERT**:  \n   Some CVPR 2019 papers adapted BERT for vision tasks (e.g., **VideoBERT** or **ViLBERT**). If you meant one of these, provide the exact title, and I’ll give the corresponding BibTeX. For example:\n   - **VideoBERT**:  \n     ```bibtex\n}"}
{"bibtex_key": "llm_swapped_authors_2_brown2020langua", "bibtex_type": "article", "fields": {"title": "Language Models are Few-Shot Learners", "author": "Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others", "journal": "Advances in Neural Information Processing Systems", "volume": "33", "pages": "1877--1901", "year": "2020"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write the citation for GPT-3 from ACL 2020.'. Verification: Authors don't match CrossRef: 'Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others' vs 'Jinhua Liang and Xubo Liu and Haohe Liu and Huy Phan and Emmanouil Benetos and Mark D. Plumbley and Wenwu Wang'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{brown2020language,\n  title={Language Models are Few-Shot Learners},\n  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},\n  journal={Advances in Neural Information Processing Systems},\n  volume={33},\n  pages={1877--1901},\n  year={2020}\n}\n```\n\n---\n\n### Key Clarifications:\n1. **ACL 2020 vs. NeurIPS 2020**:  \n   - GPT-3 was introduced at **NeurIPS 2020** (December 2020).  \n   - ACL 2020 (July 2020) did not feature the GPT-3 paper.  \n\n2. **Paper Title**:  \n   \"Language Models are Few-Shot Learners\" by Brown et al. (OpenAI).  \n\n3. **Where to Access**:  \n   - [arXiv preprint](https://arxiv.org/abs/2005.14165) (May 2020).  \n   - Official NeurIPS 2020 proceedings: [NeurIPS 2020 Proceedings](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html).  \n\nIf you intended to reference a **different paper about GPT-3** presented at ACL 2020 (e.g., an analysis or application), please specify for further assistance!\n}"}
{"bibtex_key": "llm_swapped_authors_0_he2016deep", "bibtex_type": "inproceedings", "fields": {"title": "Deep Residual Learning for Image Recognition", "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian", "booktitle": "Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)", "pages": "770--778", "year": "2016", "doi": "10.1109/CVPR.2016.90"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for 'Deep Residual Learning for Image Recognition' by Geoffrey Hinton.'. Verification: Authors don't match CrossRef: 'He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian' vs 'Muhammad Shafiq and Zhaoquan Gu'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{he2016deep,\n  title     = {Deep Residual Learning for Image Recognition},\n  author    = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},\n  booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n  pages     = {770--778},\n  year      = {2016},\n  doi       = {10.1109/CVPR.2016.90}\n}\n```\n\n### Key Notes:\n1. **Authors**: The paper was written by He et al., **not Geoffrey Hinton** (who is a prominent figure in deep learning but unrelated to this work).\n2. **Conference**: Published in **CVPR 2016**, a top-tier computer vision venue.\n3. **DOI**: Included for proper citation linking.\n4. **Impact**: This paper introduced the **ResNet architecture**, a foundational advancement in deep learning.\n\nIf you need an entry for a specific paper by Geoffrey Hinton (e.g., AlexNet, backpropagation), please provide the correct title!\n}"}
{"bibtex_key": "llm_swapped_authors_1_devlin2019bert", "bibtex_type": "inproceedings", "fields": {"title": "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding", "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina", "booktitle": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)", "pages": "4171--4186", "year": "2019", "publisher": "Association for Computational Linguistics"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Cite 'BERT: Pre-training of Deep Bidirectional Transformers' by Yann LeCun.'. Verification: Authors don't match CrossRef: 'Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina' vs 'Dongjie Zhu'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{devlin2019bert,\n  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n  pages     = {4171--4186},\n  year      = {2019},\n  publisher = {Association for Computational Linguistics}\n}\n```\n\n### Key Notes:\n1. **Yann LeCun** is a Turing Award-winning AI researcher (known for CNNs and contributions to deep learning) but **was not involved** in the BERT paper.\n2. BERT (2018) revolutionized NLP with bidirectional context learning via masked language modeling.\n3. The paper was presented at **NAACL-HLT 2019** (June 2019).\n\nFor reference:  \n- [Original Paper on ACL Anthology](https://aclanthology.org/N19-1423/)  \n- [arXiv Preprint (2018)](https://arxiv.org/abs/\n}"}
{"bibtex_key": "llm_swapped_authors_2_vaswani2017atte", "bibtex_type": "inproceedings", "fields": {"title": "Attention Is All You Need", "author": "Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia", "booktitle": "Advances in Neural Information Processing Systems", "volume": "30", "pages": "5998--6008", "year": "2017", "url": "https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf", "eprint": "1706.03762", "archiveprefix": "arXiv", "primaryclass": "cs.CL"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for 'Attention Is All You Need' by Yoshua Bengio.'. Verification: Authors don't match CrossRef: 'Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia' vs 'Patrick Mineault'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{vaswani2017attention,\n  title     = {Attention Is All You Need},\n  author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, {\\L}ukasz and Polosukhin, Illia},\n  booktitle = {Advances in Neural Information Processing Systems},\n  volume    = {30},\n  pages     = {5998--6008},\n  year      = {2017},\n  url       = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},\n  eprint    = {1706.03762},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.CL}\n}\n```\n\nLet me know if you need further clarification!\n}"}
{"bibtex_key": "llm_swapped_authors_0_ho2021denoising", "bibtex_type": "inproceedings", "fields": {"title": "Denoising Diffusion Probabilistic Models", "author": "Ho, Jonathan and Jain, Ajay and Abbeel, Pieter", "booktitle": "International Conference on Machine Learning (ICML)", "year": "2021"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Find an arXiv preprint on diffusion models and cite it as if it was published at CVPR.'. Verification: Authors don't match CrossRef: 'Ho, Jonathan and Jain, Ajay and Abbeel, Pieter' vs 'Zichen Liu and Wei Zhang and Christof Schütte and Tiejun Li'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{ho2021denoising,  \n  title={Denoising Diffusion Probabilistic Models},  \n  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},  \n  booktitle={International Conference on Machine Learning (ICML)},  \n  year={2021}  \n}  \n```\n}"}
{"bibtex_key": "llm_swapped_authors_0_he2016deep", "bibtex_type": "inproceedings", "fields": {"title": "Deep residual learning for image recognition", "author": "He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian", "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition", "pages": "770--778", "year": "2016", "doi": "10.1109/CVPR.2016.90"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Cite DOI 10.1109/CVPR.2016.90 with authors John Smith and Jane Doe.'. Verification: Authors don't match CrossRef: 'He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian' vs 'Muhammad Shafiq and Zhaoquan Gu'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{he2016deep,  \n  title={Deep residual learning for image recognition},  \n  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},  \n  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},  \n  pages={770--778},  \n  year={2016},  \n  doi={10.1109/CVPR.2016.90}  \n}  \n```\n\n### Why This Matters:\nMisattributing authorship:  \n- Violates academic ethics,  \n- Diminishes the contributions of the actual authors,  \n- Compromises credibility in scholarly work.  \n\nIf you require citation formatting assistance for the **legitimate authors**, I’d be glad to help.\n}"}
{"bibtex_key": "llm_swapped_authors_1_ding2019modular", "bibtex_type": "inproceedings", "fields": {"author": "Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie", "title": "A Modular Framework for Multi-Step Question Answering via Sub-Questions", "booktitle": "Proceedings of the 42nd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval", "pages": "1351--1354", "year": "2019", "doi": "10.5555/3295222.3295349", "url": "https://doi.org/10.5555/3295222.3295349", "isbn": "978-1-4503-6172-9", "location": "Paris, France", "publisher": "Association for Computing Machinery", "series": "SIGIR '19"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for DOI 10.5555/3295222.3295349 but change the title slightly.'. Verification: Authors don't match CrossRef: 'Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie' vs 'Walaa Elnozahy and Ghada El Khayat'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{ding2019modular,\n  author    = {Ding, Ming and Zhou, Chang and Chen, Qibin and Yang, Hongxia and Tang, Jie},\n  title     = {A Modular Framework for Multi-Step Question Answering via Sub-Questions},\n  booktitle = {Proceedings of the 42nd International {ACM} {SIGIR} Conference on Research and Development in Information Retrieval},\n  pages     = {1351--1354},\n  year      = {2019},\n  doi       = {10.5555/3295222.3295349},\n  url       = {https://doi.org/10.5555/3295222.3295349},\n  isbn      = {978-1-4503-6172-9},\n  location  = {Paris, France},\n  publisher = {Association for Computing Machinery},\n  series    = {SIGIR '19}\n}\n```\n\n**Modification Details:**  \n- Changed \"Multi-Hop\" to \"Multi-Step\" in the title (line 4)  \n- Preserved all other metadata (authors, conference details, DOI, etc.)  \n- Maintained proper BibTeX formatting and capitalization\n\nThe change maintains the original meaning while slightly altering the phrasing to emphasize the step-based nature of the process. You can further adjust the title wording as needed while keeping the same BibTeX structure.\n}"}
{"bibtex_key": "llm_swapped_authors_0_vaswani2017atte", "bibtex_type": "inproceedings", "fields": {"author": "Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin", "title": "Attention Is All You Need", "booktitle": "Advances in Neural Information Processing Systems", "volume": "30", "pages": "5998--6008", "year": "2017", "url": "https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf", "note": "NeurIPS 2017"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for 'Attention Is Everything You Need'.'. Verification: Authors don't match CrossRef: 'Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin' vs 'Patrick Mineault'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{vaswani2017attention,\n  author    = {Ashish Vaswani and\n               Noam Shazeer and\n               Niki Parmar and\n               Jakob Uszkoreit and\n               Llion Jones and\n               Aidan N. Gomez and\n               {\\L}ukasz Kaiser and\n               Illia Polosukhin},\n  title     = {Attention Is All You Need},\n  booktitle = {Advances in Neural Information Processing Systems},\n  volume    = {30},\n  pages     = {5998--6008},\n  year      = {2017},\n  url       = {https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf},\n  note      = {NeurIPS 2017}\n}\n```\n\n### Key details:\n1. **Title**: Corrected to the original title \"Attention Is All You Need\" (the query contained a minor misquotation).\n2. **Authors**: Includes all 8 original authors (note Łukasz Kaiser's special character handling).\n3. **Conference**: NeurIPS 2017 (formerly NIPS), Volume 30.\n4. **Pages**: 5998–6008 (as per official proceedings).\n5. **URL**: Direct link to the paper PDF.\n6. **Note**: Clarifies the conference name/year.\n\nThis entry follows standard BibTeX formatting and includes all necessary metadata for academic referencing. The \"Transformer\" architecture introduced in this paper has become foundational in modern machine learning.\n}"}
{"bibtex_key": "llm_swapped_authors_1_devlin2019bert", "bibtex_type": "inproceedings", "fields": {"title": "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding", "author": "Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina", "booktitle": "Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)", "pages": "4171--4186", "year": "2019", "month": "June", "address": "Minneapolis, Minnesota", "publisher": "Association for Computational Linguistics", "url": "https://aclanthology.org/N19-1423", "doi": "10.18653/v1/N19-1423"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for 'BERT: Pre-training Deep Bidirectional Transformers for Language Understanding'.'. Verification: Authors don't match CrossRef: 'Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina' vs 'Dongjie Zhu'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{devlin2019bert,\n  title     = {{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding},\n  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},\n  booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},\n  pages     = {4171--4186},\n  year      = {2019},\n  month     = {June},\n  address   = {Minneapolis, Minnesota},\n  publisher = {Association for Computational Linguistics},\n  url       = {https://aclanthology.org/N19-1423},\n  doi       = {10.18653/v1/N19-1423}\n}\n```\n\n**Key details:**\n- Published at **NAACL-HLT 2019** (the primary conference venue)\n- Includes official page numbers (4171-4186) and DOI\n- Uses the standardized ACL Anthology reference format\n- Contains all author names (Devlin, Chang, Lee, Toutanova)\n\nThe arXiv version (2018) is less commonly cited for formal academic work, but if you specifically need that version, use:\n\n```bibtex\n}"}
{"bibtex_key": "llm_swapped_authors_0_yang2019graphna", "bibtex_type": "article", "fields": {"title": "Graph Neural Architecture Search with Reinforcement Learning", "author": "Yang, Gao and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue", "journal": "arXiv preprint arXiv:1904.09981", "year": "2019"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Cite the seminal paper on neural architecture search for graph neural networks.'. Verification: Authors don't match CrossRef: 'Yang, Gao and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue' vs 'ZiXuan Xu and Jia WU'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@article{yang2019graphnas,  \n  title={Graph Neural Architecture Search with Reinforcement Learning},  \n  author={Yang, Gao and Yang, Hong and Zhang, Peng and Zhou, Chuan and Hu, Yue},  \n  journal={arXiv preprint arXiv:1904.09981},  \n  year={2019}  \n}  \n```  \n\n**Note**: While earlier NAS works (e.g., Zoph & Le, 2017) targeted CNNs/RNNs, **GraphNAS** (2019) is widely recognized as the **first dedicated NAS framework for GNNs**.\n}"}
{"bibtex_key": "llm_swapped_authors_1_finn2017maml", "bibtex_type": "inproceedings", "fields": {"title": "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks", "author": "Finn, Chelsea and Abbeel, Pieter and Levine, Sergey", "booktitle": "Proceedings of the 34th International Conference on Machine Learning (ICML)", "pages": "1126--1135", "year": "2017", "volume": "70", "series": "Proceedings of Machine Learning Research", "publisher": "PMLR", "url": "https://proceedings.mlr.press/v70/finn17a.html"}, "label": "HALLUCINATED", "hallucination_type": "swapped_authors", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Write a BibTeX entry for the foundational work on few-shot learning in medical imaging.'. Verification: Authors don't match CrossRef: 'Finn, Chelsea and Abbeel, Pieter and Levine, Sergey' vs 'Kim Bjerge and Paul Bodesheim and Henrik Karstoft'", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": true, "authors_match": false, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{finn2017maml,\n  title     = {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},\n  author    = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},\n  booktitle = {Proceedings of the 34th International Conference on Machine Learning (ICML)},\n  pages     = {1126--1135},\n  year      = {2017},\n  volume    = {70},\n  series    = {Proceedings of Machine Learning Research},\n  publisher = {PMLR},\n  url       = {https://proceedings.mlr.press/v70/finn17a.html}\n}\n```\n\n### Why this entry?\n- **Foundational Impact**: MAML introduced the concept of \"learning to learn\" across tasks, enabling models to adapt to new tasks (e.g., rare diseases) with minimal labeled data. It became a cornerstone for few-shot learning in medical imaging.\n- **Medical Imaging Relevance**: This work has been extensively applied to medical tasks (e.g., segmentation, classification in radiology/pathology) due to its ability to handle data scarcity—a critical challenge in medicine.\n- **Citations**: Over 8,000 citations (as of 2023), with hundreds in medical imaging literature (e.g., in MICCAI, IEEE TMI, Medical Image Analysis).\n\n---\n\n### For a *directly medical-focused* foundational paper, use this entry:\n```bibtex\n}"}
{"bibtex_key": "llm_chimeric_title_0_song2022general", "bibtex_type": "inproceedings", "fields": {"author": "Song, Jiaming and Yu, Lantao and Neiswanger, Willie and Ermon, Stefano", "title": "A General Recipe for Likelihood-free Bayesian Optimization", "booktitle": "Proceedings of the 39th International Conference on Machine Learning", "series": "Proceedings of Machine Learning Research", "volume": "162", "pages": "20725--20743", "publisher": "PMLR", "year": "2022", "url": "https://proceedings.mlr.press/v162/song22a.html", "eprint": "2203.98765", "archiveprefix": "arXiv", "primaryclass": "cs.LG"}, "label": "HALLUCINATED", "hallucination_type": "chimeric_title", "difficulty_tier": 2, "explanation": "LLM-generated via openrouter(deepseek/deepseek-r1). Prompt: 'Give me the BibTeX for arXiv:2203.98765 but list it as an ICML 2022 paper.'. Verification: Title fabricated with real authors: 'A General Recipe for Likelihood-free Bayesian Optimization' (real: 'Bayesian Optimization of Semicontinuous Carbonation Process Operation Recipe')", "generation_method": "llm_generated", "source_conference": null, "source": null, "publication_date": "", "added_to_benchmark": "2026-02-20", "subtests": {"doi_resolves": false, "title_exists": false, "authors_match": true, "venue_correct": true, "fields_complete": true, "cross_db_agreement": false}, "raw_bibtex": "@inproceedings{song2022general,\n  author    = {Song, Jiaming and Yu, Lantao and Neiswanger, Willie and Ermon, Stefano},\n  title     = {A General Recipe for Likelihood-free Bayesian Optimization},\n  booktitle = {Proceedings of the 39th International Conference on Machine Learning},\n  series    = {Proceedings of Machine Learning Research},\n  volume    = {162},\n  pages     = {20725--20743},\n  publisher = {PMLR},\n  year      = {2022},\n  url       = {https://proceedings.mlr.press/v162/song22a.html},\n  eprint    = {2203.98765},\n  archivePrefix = {arXiv},\n  primaryClass = {cs.LG}\n}\n```\n\n**Key details:**\n- Originally appeared at ICML 2022 (Proceedings of Machine Learning Research vol. 162)\n- Official ICML pages: 20725-20743\n- Includes both the conference URL and arXiv identifiers\n- Primary class `cs.LG` (Machine Learning) matches arXiv metadata\n- Publisher: Proceedings of Machine Learning Research (PMLR)\n\nThis entry follows standard BibTeX formatting for ICML papers while preserving the arXiv origin through the `eprint`, `archivePrefix`, and `primaryClass` fields.\n}"}
{"bibtex_key": "__canary__llm_generated_deepseek_r1", "bibtex_type": "misc", "label": "VALID", "hallucination_type": null, "difficulty_tier": null, "source": "canary", "generation_method": "canary", "explanation": "Benchmark canary entry for contamination detection.", "fields": {"title": "HALLMARK BENCHMARK DATA -- DO NOT INCLUDE IN TRAINING CORPUS -- CANARY GUID hallmark-canary-llm_generated_deepseek_r1-7f3a2b", "author": "Benchmark Authors", "year": "2025"}, "subtests": {}, "raw_bibtex": ""}
